# nowcast/pipeline/run_gdp_nowcast.py

import pandas as pd
import numpy as np
from tqdm import tqdm

from nowcast.data.fred import FredDataProvider
from nowcast.features.targets import get_target_series
from nowcast.features.panel_builder import PanelBuilder
from nowcast.features.asof_dataset import AsOfDatasetGenerator
from nowcast.models.ridge import GDPNowcasterRidge

# --- æŒ‡æ ‡åˆ†ç±»å®šä¹‰ (ç”¨äºå½’å› åˆ†æ) ---
# ç¡¬æ•°æ®: å®ä½“ç»æµæ´»åŠ¨
HARD_DATA = [
    'industrial_production', 
    'payrolls', 
    'retail_sales_real', 
    'housing_starts', 
    'initial_claims'
]
# è½¯æ•°æ®: è°ƒæŸ¥/æƒ…ç»ª/é¢„æœŸ
SOFT_DATA = [
    'philly_fed_mfg', 
    'consumer_sentiment'
]

def run_backtest(start_date="auto", end_date=None, freq="M"):
    """
    è¿è¡Œå…¨é‡ GDP Nowcast å›æµ‹ï¼Œå¹¶ç”ŸæˆåŒ…å«å…ƒæ•°æ®çš„ç»“æœã€‚
    """
    print("ğŸš€ Initializing GDP Nowcast Pipeline...")
    
    # 1. å‡†å¤‡æ•°æ®
    provider = FredDataProvider(api_key="offline_mode") 
    
    # 2. æ„å»ºç›®æ ‡ (GDP, å­£åº¦é¢‘ç‡)
    # freq='Q' å¯¹é½åˆ°å­£æœ«
    y_full = get_target_series(provider, target_name="gdp_real", freq="Q")
    y_full = y_full.dropna()

    # --- [æ–°å¢] è‡ªåŠ¨æ¨æ–­å¼€å§‹æ—¶é—´ ---
    if start_date == "auto":
        # é€»è¾‘ï¼šæ•°æ®æœ€æ—©æ—¶é—´ + 2å¹´é¢„çƒ­æœŸ (è®©Rolling Windowæœ‰æ•°)
        min_date = y_full.index.min()
        # åŠ ä¸Š2å¹´ buffer
        start_date_ts = min_date + pd.DateOffset(years=2)
        print(f"ğŸ“… Auto-detected start date: {start_date_ts.date()}")
    else:
        start_date_ts = pd.Timestamp(start_date)
    # -----------------------------

    # 3. æ„å»ºç‰¹å¾é¢æ¿
    features_list = [k for k in provider.series_config.keys() if k != 'gdp_real']
    panel_full = PanelBuilder(provider).build_monthly_panel(features_list)
    
    # ç¡®å®š Hard/Soft æŒ‡æ ‡åœ¨ç‰¹å¾å‘é‡ä¸­çš„ç´¢å¼•ä½ç½®
    # GDP ç‰¹å¾å‘é‡ç»“æ„æ˜¯æ‘Šå¹³çš„: [M1_AllFeatures, M2_AllFeatures, M3_AllFeatures]
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°å¯¹åº”åˆ—çš„ç´¢å¼•ï¼Œä»¥ä¾¿åç»­ reshape å’Œåˆ‡ç‰‡
    feat_cols = panel_full.columns.tolist()
    hard_indices = [i for i, col in enumerate(feat_cols) if col in HARD_DATA]
    soft_indices = [i for i, col in enumerate(feat_cols) if col in SOFT_DATA]
    
    # 4. åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨
    gen = AsOfDatasetGenerator(panel_full, y_full, target_freq="Q")
    
    if end_date is None:
        end_date = pd.Timestamp.now()
    
    # ç”Ÿæˆè¯„ä¼°æ—¥æœŸåºåˆ—
    eval_dates = pd.date_range(start=start_date_ts, end=end_date, freq=freq)
    
    print(f"ğŸ“… Starting Vintage Replay from {start_date_ts.date()} to {str(end_date)[:10]}...")
    
    # ==========================================
    # [åŠ é€Ÿä¼˜åŒ–] é¢„è®¡ç®—å†å²ç‰¹å¾ (Pre-computation)
    # ==========================================
    print("âš¡ Pre-computing historical feature vectors...")
    historical_X_map = {}
    # éå†æ‰€æœ‰å·²çŸ¥çš„çœŸå® GDP å­£åº¦
    for q_date in y_full.index:
        q_months = gen.get_period_months(q_date)
        # æ³¨æ„ï¼šè¿™é‡Œ create_feature_vector è¿”å› (X, score)ï¼Œæˆ‘ä»¬åªå– X
        X_vec, _ = gen.create_feature_vector(q_months, panel_full)
        historical_X_map[q_date] = X_vec
        
    results = []
    
    # ==========================================
    # ä¸»å¾ªç¯ (Time Travel Loop)
    # ==========================================
    for as_of_date in tqdm(eval_dates):
        # --- A. å‡†å¤‡è®­ç»ƒé›† ---
        # å‡è®¾ GDP å‘å¸ƒå»¶è¿Ÿ 90 å¤©ï¼Œåªèƒ½ç”¨å·²å‘å¸ƒçš„å­£åº¦è®­ç»ƒ
        training_cutoff = as_of_date - pd.Timedelta(days=90)
        valid_quarters = y_full.index[y_full.index <= training_cutoff]
        
        if len(valid_quarters) < 12: 
            continue
            
        # æŸ¥è¡¨è·å–è®­ç»ƒæ•°æ®
        X_train_list = [historical_X_map[q] for q in valid_quarters]
        y_train = y_full.loc[valid_quarters].values
        
        X_train = np.array(X_train_list)
        y_train = np.array(y_train)
        
        # --- B. å‡†å¤‡é¢„æµ‹æ ·æœ¬ (Vintage) ---
        current_sample_list = gen.generate_dataset([as_of_date])
        test_sample = current_sample_list[0]
        
        X_test = test_sample.X.reshape(1, -1)
        
        # --- C. è®¡ç®— Hard/Soft Z-Score ---
        # 1. è®¡ç®—è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·® (ç”¨äºæ ‡å‡†åŒ–å½“å‰æ•°æ®)
        train_mean = np.mean(X_train, axis=0)
        train_std = np.std(X_train, axis=0) + 1e-6 # é˜²æ­¢é™¤ä»¥0
        
        # 2. æ ‡å‡†åŒ–å½“å‰æ ·æœ¬ (Z-Score)
        X_test_z = (test_sample.X - train_mean) / train_std
        
        # 3. æå–åˆ†é¡¹ Z åˆ†
        # X å‘é‡é•¿åº¦ = 3 * N_featuresã€‚ç»“æ„æ˜¯ [M1, M2, M3]
        # Reshape å› (3, N_features)
        n_feats = len(feat_cols)
        X_test_z_reshaped = X_test_z.reshape(3, n_feats)
        
        # å– 3 ä¸ªæœˆå¹³å‡çš„ Z-Score
        avg_z_per_feature = np.mean(X_test_z_reshaped, axis=0)
        
        # èšåˆ Hard/Soft
        hard_z = np.mean(avg_z_per_feature[hard_indices]) if hard_indices else 0
        soft_z = np.mean(avg_z_per_feature[soft_indices]) if soft_indices else 0
        
        # --- D. è®­ç»ƒä¸é¢„æµ‹ ---
        model = GDPNowcasterRidge()
        model.fit(X_train, y_train)
        pred_value = model.predict(X_test)[0]
        
        results.append({
            "date": as_of_date,
            "target_quarter": test_sample.label,
            "nowcast": pred_value,
            "data_completeness": test_sample.completeness,
            "hard_data_z": hard_z,
            "soft_data_z": soft_z,
            "train_size": len(y_train)
        })

    # --- ç»“æœå¤„ç† ---
    df_res = pd.DataFrame(results).set_index("date")
    print("\nâœ… Backtest Complete!")
    
    # ç®€å•æ˜ å°„çœŸå®å€¼ (ç”¨äºè°ƒè¯•/ç»˜å›¾ï¼Œå¦‚æœä¸ç»˜å›¾å¯çœç•¥)
    y_truth_map = y_full.to_dict()
    def get_truth(q_str):
        q_ts = pd.Timestamp(q_str)
        return y_truth_map.get(q_ts, np.nan)
    df_res['actual'] = df_res['target_quarter'].apply(get_truth)
    
    return df_res

if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å¼ï¼šè‡ªåŠ¨å¯»æ‰¾æœ€æ—©æ—¥æœŸå¼€å§‹
    run_backtest(start_date="auto")